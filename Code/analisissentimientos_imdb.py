# -*- coding: utf-8 -*-
"""AnalisisSentimientos_IMDB.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VQcX8WfR4OhBQhVatdgyatIVCxfRVbZh

# Librerías básicas
"""

import dill

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import threading 

"""# Descargar y leer datos"""

import os
import tarfile
import urllib.request

# Descargar dataset
url = "https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
filename = "aclImdb_v1.tar.gz"
if not os.path.exists(filename):
    print("Descargando dataset...")
    urllib.request.urlretrieve(url, filename)

# Descomprimir
if not os.path.exists("aclImdb"):
    print("Descomprimiendo...")
    with tarfile.open(filename, "r:gz") as tar:
        tar.extractall()

# Cargar datos
def load_reviews_from_folder_with_set(folder_path, sentiment, dataset_set):
        data = []
        for file in os.listdir(folder_path):
            with open(os.path.join(folder_path, file), encoding="utf-8") as f:
                review = f.read()
                data.append((review, sentiment, dataset_set))
        return data

# Datos de train y test
base_path = "aclImdb"
train_pos = load_reviews_from_folder_with_set(os.path.join(base_path, "train/pos"), 1, "train")
train_neg = load_reviews_from_folder_with_set(os.path.join(base_path, "train/neg"), 0, "train")
test_pos = load_reviews_from_folder_with_set(os.path.join(base_path, "test/pos"), 1, "test")
test_neg = load_reviews_from_folder_with_set(os.path.join(base_path, "test/neg"), 0, "test")

# DataFrame
# Crear DataFrame con la nueva columna
all_reviews = train_pos + train_neg + test_pos + test_neg
df = pd.DataFrame(all_reviews, columns=["review", "sentiment", "dataset_set"])
print(f"Total de reseñas cargadas: {len(df)}")

# Guardar a CSV
df.to_csv("imdb_reviews.csv", index=False)
print("Archivo imdb_reviews.csv guardado correctamente.")

df.to_csv("imdb_reviews.csv", index=False)

df = pd.read_csv("imdb_reviews.csv")
df

"""# Explorar datos"""

print(df.shape)

print(df.info())

# Número de datos por clase
print("Distribución de sentimientos:")
print(df['sentiment'].value_counts())

# Columna que contiene la longitud de la reseña
df['length'] = df['review'].apply(lambda x: len(str(x).split()))
df

# Función para calcular resumen estadístico
from scipy.stats import skew

def cerrarGrafica():
    plt.close()

def resumen_estadistico(df):
  re = pd.DataFrame({
    'Media': df.mean(),
    'Mediana': df.median(),
    'Moda': df.apply(lambda x: x.mode().iloc[0]),
    'Desviación estándar': df.std(ddof=1),
    'Varianza': df.var(ddof=1),
    'Mínimo': df.min(),
    'Máximo': df.max(),
    'Asimetría': df.apply(skew)
  })
  return re.round(2)

print(resumen_estadistico(df.groupby('dataset_set')['length']))

df['length'].hist(bins=40, edgecolor='black')
plt.title('Distribución de la longitud de las reseñas')
plt.xlabel('Número de palabras')
plt.ylabel('Frecuencia')
plt.savefig("longitud-reseñas.jpg")
threading.Timer(5.0,cerrarGrafica).start()
plt.show()

print("Ejemplo de reseña POSITIVA:")
print(df[df['sentiment'] == 1]['review'].iloc[0])

print("\nEjemplo de reseña NEGATIVA:")
print(df[df['sentiment'] == 0]['review'].iloc[0])

# Longitud promedio de reseñas por clase (positivas y negativas)
lenght_by_sentiment = df.groupby('sentiment')['length'].mean().round(2)
print(lenght_by_sentiment)

"""# Limpiar y  preprocesar reseñas"""

import re
import nltk
import xgboost
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt')

stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    if not isinstance(text, str):
        return ""

    # Conservar signos de exclamación/interrogación (importantes para sentimiento)
    text = re.sub(r'([!?])', r' \1 ', text)  # Añade espacios alrededor
    # Eliminar URLs pero conservar números y algunas puntuaciones
    text = re.sub(r'http\S+|@\S+|#', '', text)
    # Convertir emojis a texto
    #text = emoji.demojize(text)
    # Minúsculas y eliminar caracteres especiales excepto !?
    text = re.sub(r'[^a-z!?\s]', '', text.lower())

    # Usar Lemmatization (mejor que Stemming)
    lemmatizer = WordNetLemmatizer()
    tokens = text.split()
    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]

    return ' '.join(tokens)

from collections import Counter

df['clean_review'] = df['review'].apply(preprocess_text)

positive_reviews = df[df['sentiment'] == 1]['clean_review']
negative_reviews = df[df['sentiment'] == 0]['clean_review']

positive_words = ' '.join(positive_reviews).split()
negative_words = ' '.join(negative_reviews).split()

pos_counts = Counter(positive_words)
neg_counts = Counter(negative_words)

top_pos = pos_counts.most_common(40)
top_neg = neg_counts.most_common(40)

def plot_top_words(word_freq, title, color, filename):
    words, freqs = zip(*word_freq)
    plt.figure(figsize=(10,5))
    plt.bar(words, freqs, color=color)
    plt.xticks(rotation=45, ha='right')
    plt.title(title)
    plt.ylabel("Frecuencia")
    plt.grid(axis='y')
    plt.tight_layout()
    plt.savefig(filename)
    threading.Timer(5.0,cerrarGrafica).start()
    plt.show()

plot_top_words(top_pos, "Palabras más comunes en reseñas POSITIVAS después de preprocesar", "green", "palabras_mas_comunes_POSITIVAS_despues_procesar")
plot_top_words(top_neg, "Palabras más comunes en reseñas NEGATIVAS después de preprocesar", "red", "palabras_mas_comunes_NEGATIVAS_despues_procesar")

"""# Dividir datos"""

x = df['clean_review']
y = df['sentiment']

from sklearn.model_selection import train_test_split

x_train_val, x_test, y_train_val, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.25, random_state=42)

print(f"Dimensiones de x_train: {x_train.shape}")
print(f"Dimensiones de x_val: {x_val.shape}")
print(f"Dimensiones de x_test: {x_test.shape}")
print(f"Dimensiones de y_train: {y_train.shape}")
print(f"Dimensiones de y_val: {y_val.shape}")
print(f"Dimensiones de y_test: {y_test.shape}")

from sklearn.model_selection import StratifiedShuffleSplit

subconjunto = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)

"""# TF-IDF"""

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vectorizer_viz = TfidfVectorizer(max_df=0.9, min_df=0.005, ngram_range=(1,1))
tfidf_matrix = tfidf_vectorizer_viz.fit_transform(x)

S = np.array(tfidf_matrix.sum(axis=0))[0]
S_sorted = sorted(S, reverse=True)
plt.plot(sorted(S, reverse=True), '.k')
plt.ylabel('Puntajes TF-IDF por palabra')
plt.xlabel('Rango de palabras')
plt.title('Distribución de puntajes TF-IDF')
plt.savefig("TF-IDF-per-word.jpg")
threading.Timer(5.0,cerrarGrafica).start()
plt.show()

from sklearn.pipeline import make_pipeline
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.model_selection import GridSearchCV, validation_curve
from sklearn.preprocessing import MaxAbsScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix


tfidf = TfidfVectorizer(
    max_df=0.85,  # Eliminar palabras muy frecuentes (posible ruido)
    min_df=10,    # Palabras que aparezcan en al menos 10 documentos
    ngram_range=(1, 2),  # Bigramas pueden capturar contexto
    max_features=10000   # Limitar dimensionalidad
)

"""# Naive Bayes Multinomial"""

print("=== PROCESS NAIVE BAYES",flush=True)
"""Definimos pipeline"""


pipelineMNB = make_pipeline(tfidf, MaxAbsScaler(), MultinomialNB(alpha=1.0))
pipelineMNB.fit(x_train, y_train)

"""Aplicamos validation_curve"""


param_grid_MNB = {
    'tfidfvectorizer__ngram_range': [(1, 1), (1, 2)],  
    'multinomialnb__alpha': [0.1, 1.0],      
    'multinomialnb__fit_prior': [True, False]        
}

grid_search_MNB = GridSearchCV(pipelineMNB, param_grid_MNB, cv=subconjunto, scoring='accuracy', n_jobs=-1, verbose=3)
grid_search_MNB.fit(x_train, y_train)
best_model_MNB = grid_search_MNB.best_estimator_
print("Mejores parámetros encontrados:", grid_search_MNB.best_params_)
print("Mejor precisión:", grid_search_MNB.best_score_)


y_val_pred = best_model_MNB.predict(x_val)

print("Accuracy:", accuracy_score(y_val, y_val_pred))
print(classification_report(y_val, y_val_pred))

cm = confusion_matrix(y_val, y_val_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negativo', 'Positivo'], yticklabels=['Negativo', 'Positivo'])
plt.xlabel('Predicción')
plt.ylabel('Real')
plt.title('Matriz de Confusión')
plt.savefig("Confusion-Matrix-MNB.jpg")
threading.Timer(5.0,cerrarGrafica).start()
plt.show()

dill.dump_session('MNB.pkl')    
    
"""# Regresión Logística"""
from sklearn.linear_model import LogisticRegression
print("=== PROCESS REGRESION LOGISTICA",flush=True)
pipelineLR = make_pipeline(tfidf, MaxAbsScaler(), LogisticRegression(max_iter=1000, random_state=42))
pipelineLR.fit(x_train, y_train)

"""Encontrar mejor C usando GridSearchCV"""

param_grid_LR = {
    'logisticregression__C': np.logspace(-1, 1, 20),  # 20 valores entre 0.1 y 10
    'logisticregression__penalty': ['l1', 'l2'],
    'tfidfvectorizer__ngram_range': [(1,1), (1,2)]
    }

grid_search_LR = GridSearchCV(pipelineLR, param_grid_LR, cv=subconjunto, scoring='accuracy', n_jobs=-1, verbose=3)
grid_search_LR.fit(x_train, y_train)
best_model_LR = grid_search_LR.best_estimator_
print("Mejores parámetros encontrados:", grid_search_LR.best_params_)
print("Mejor precisión:", grid_search_LR.best_score_)

"""Predicciones en x_val con best_model_LR"""

y_val_pred =  best_model_LR.predict(x_val)

print("Accuracy:", accuracy_score(y_val, y_val_pred))
print(classification_report(y_val, y_val_pred))

cm = confusion_matrix(y_val, y_val_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negativo', 'Positivo'], yticklabels=['Negativo', 'Positivo'])
plt.xlabel('Predicción')
plt.ylabel('Real')
plt.title('Matriz de Confusión (LR en Validación)')
plt.savefig("Confusion-Matrix-LR.jpg")
threading.Timer(5.0,cerrarGrafica).start()
plt.show()

dill.dump_session('MNB_LR.pkl')    

"""# Máquinas de soporte vectorial (SVM)"""
from sklearn.svm import SVC

print("=== PROCESS SVM",flush=True)
pipelineSVM = make_pipeline(tfidf, MaxAbsScaler(), SVC())

param_grid_SVM = {
    'svc__C': [0.1, 1, 10],
    'svc__kernel': ['linear', 'rbf'],
    'svc__gamma': ['scale', 'auto', 0.01]
    }

grid_search_SVM = GridSearchCV(pipelineSVM, param_grid_SVM, cv=subconjunto, scoring='accuracy', n_jobs=-1, verbose=3)
grid_search_SVM.fit(x_train, y_train)
print("Mejores parámetros encontrados:", grid_search_SVM.best_params_)
print("Mejor precisión:", grid_search_SVM.best_score_)
best_model_SVM = grid_search_SVM.best_estimator_

"""Predicciones en x_val con best_model_SVM"""

y_val_pred = best_model_SVM.predict(x_val)

print("Accuracy:", accuracy_score(y_val, y_val_pred))
print(classification_report(y_val, y_val_pred))

cm = confusion_matrix(y_val, y_val_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negativo', 'Positivo'], yticklabels=['Negativo', 'Positivo'])
plt.xlabel('Predicción')
plt.ylabel('Real')
plt.title('Matriz de Confusión')
plt.savefig("Confusion-Matrix-SVM.jpg")
threading.Timer(5.0,cerrarGrafica).start()
plt.show()
    
dill.dump_session('MNB_LR_SVM.pkl')    

"""# XG Boost"""
from xgboost import XGBClassifier

print("=== PROCESS XGBOOST",flush=True)

pipelineXGB = make_pipeline(tfidf, MaxAbsScaler(),XGBClassifier(n_estimators=200,subsample=0.6,colsample_bytree=0.8,random_state=42))
pipelineXGB.fit(x_train, y_train)

param_grid_XGB = {
    'xgbclassifier__learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],
    'xgbclassifier__max_depth': [3, 4, 5, 6, 7],
    #'xgbclassifier__colsample_bytree': [0.5, 0.7]
    }

grid_search_XGB = GridSearchCV(pipelineXGB, param_grid_XGB, cv=subconjunto, scoring='accuracy', n_jobs=-1, verbose=3)
grid_search_XGB.fit(x_train, y_train)
print("Mejores parámetros encontrados:", grid_search_XGB.best_params_)
print("Mejor precisión:", grid_search_XGB.best_score_)
best_model_XGB = grid_search_XGB.best_estimator_

"""Evaluar modelo con conjunto de validación"""

y_val_pred = best_model_XGB.predict(x_val)

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

print("Accuracy:", accuracy_score(y_val, y_val_pred))
print(classification_report(y_val, y_val_pred))

cm = confusion_matrix(y_val, y_val_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negativo', 'Positivo'], yticklabels=['Negativo', 'Positivo'])
plt.xlabel('Predicción')
plt.ylabel('Real')
plt.title('Matriz de Confusión')
plt.savefig("Confusion-Matrix-XGB.jpg")
threading.Timer(5.0,cerrarGrafica).start()
plt.show()

dill.dump_session('MNB_LR_SVM_XGB.pkl')    
   
"""# Evalución Final en conjunto de prueba (x_test)"""

print("=== EVALUACION FINAL",flush=True)

modelos_finales = {
    "Naive Bayes Multinomial": best_model_MNB,
    "Regresión Logística": best_model_LR,
    "SVM": best_model_SVM,
    "XG Boost": best_model_XGB}

for nombre_modelo, modelo in modelos_finales.items():
    y_test_pred = modelo.predict(x_test)
    accuracy = accuracy_score(y_test, y_test_pred)
    report = classification_report(y_test, y_test_pred)
    print(f"Accuracy en conjunto de prueba ({nombre_modelo}):", accuracy)
    print(f"Classification Report en conjunto de prueba ({nombre_modelo}):", report)

    cm_test = confusion_matrix(y_test, y_test_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', xticklabels=['Negativo', 'Positivo'], yticklabels=['Negativo', 'Positivo'])
    plt.xlabel('Predicción')
    plt.ylabel('Real')
    plt.title(f'Matriz de Confusión en el Conjunto de Prueba ({nombre_modelo})')
    plt.savefig(f'Confusion-Matrix-Test-{nombre_modelo}.jpg')
    threading.Timer(5.0,cerrarGrafica).start()
    plt.show()

dill.dump_session('Final_Eval.pkl')    
